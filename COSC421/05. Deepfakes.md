# 05. Deepfakes

<!--
Last week, recap:

- Anomaly detection
- Supervised
  - Works in most situations
  - Requires manual labeling and a lot of data
- Unsupervised
  - Use data to determine what is 'normal' and find anomalies
-->

Deepfakes:

- AI to transplant faces onto other person's face
- Also can fake:
  - Voice
  - Gait
    - Humans very sensitive to gait; character animation is difficult which is why motion capture is usually used
- 2017: `r/deepfakes`, mostly for porn
  - Existed previously in research institutions since the 90s


Theory:

- Deep learning used to train generative neural networks such as:
  - Autoencoders
  - Generative adversarial networks (GANs)

Autoencoders:

- Reduce image to lower-dimensional **latent space**
  - Contains **key features** about facial features and body pose
- Decoder: reconstructs image from latent representation
- Train model for a specific target
  - Match keypoints to superimpose the target's facial features

Generative adversal networks (GANs):

- GAN trains generator (decoder) and discriminator
- Generate creates new images; discriminator attempts to determine if the image is generated or not
- Makes them realistic and difficult to spot deepfakes
  - Researchers have made algorithms to detect this
    - Shadow/lighting inconsistencies
    - Light reflections in eyes
    - Wael AbdAlmageed:
      - 1st gen: Spatio-temporal inconsistencies (using RNNs)
      - 2nd gen: end-to-end deep networks to detect frequency information
        - One branch amplifies low frequency information with the Laplacian of Gaussian
        - The second branch propagates color information
    - DARPA competitions
  - But these can then be used to update the discriminator

Use-cases:

- Movies: dead actors/de-aging
- Identity fraud
  - Online/app video-based identification (liveness tests)
- Porn
- Blackmail
  - Revenge porn
  - Related: if there is real comprimising footage of a victim, they can just claim that it is a deepfake
- Fake news
  - Declaring war as political leaders
- Sockpuppets
  - Users active online and in traditional media that don't exist
  - Video footage of people considered to be trustworthy
  - Example: 'Oliver Taylor' persona

Exploitation, intimidation, personal sabotage

Prevention:

- Digital signing of images/videos from cameras and smartphones
  - But can also be used to track down dissidents

